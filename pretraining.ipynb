{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "from transformers import AutoImageProcessor, AutoTokenizer\n",
    "class CompDataset(Dataset):\n",
    "    def __init__(self, pickle_file,image_path_root):\n",
    "        super().__init__()\n",
    "        with open(pickle_file, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "        self.components = []\n",
    "        self.image_paths = []\n",
    "        for k in data.keys():\n",
    "            self.components.extend(data[k]['components'])\n",
    "            self.image_paths.extend([ f\"{os.path.join(image_path_root,k)}_page-{comp['page']}.png\" for comp in data[k]['components']])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.components)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        comp = self.components[index]\n",
    "        img = Image.open(self.image_paths[index]).convert(\"RGB\")\n",
    "        bbox = comp['bbox']\n",
    "        cropped_img = transforms.functional.crop(img,top=bbox[1],left=bbox[0],height=bbox[3],width=bbox[2])\n",
    "        try:\n",
    "            text = comp['text']\n",
    "        except:\n",
    "            text = comp['category']\n",
    "        return (cropped_img, text, comp['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def collate_fn(batch):\n",
    "    images = [e[0] for e in batch]\n",
    "    text = [e[1] for e in batch]\n",
    "    labels = torch.tensor([e[2] for e in batch], dtype=torch.long)\n",
    "    return (images, text, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CompDataset('train_data.pkl','train/train')\n",
    "val_dataset = CompDataset('val_data.pkl','val/val')\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=1, shuffle=True,collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"nielsr/donut-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaModel, DonutSwinModel\n",
    "class FusionLayer(nn.Module):\n",
    "    def __init__(self, visual_dim, text_dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.visual_dim = visual_dim\n",
    "        self.text_dim = text_dim\n",
    "        self.mhsa = nn.MultiheadAttention(self.visual_dim,num_heads,kdim=text_dim,batch_first=True)\n",
    "        self.fc = nn.Sequential(nn.Linear(self.visual_dim,self.visual_dim*2),nn.GELU(),nn.Linear(self.visual_dim*2,self.visual_dim))\n",
    "        self.layer_norm = nn.LayerNorm(self.visual_dim)\n",
    "\n",
    "    def forward(self, visual_embedding, textual_embedding):\n",
    "        visual_embedding = visual_embedding.unsqueeze(1)\n",
    "        textual_embedding = textual_embedding.unsqueeze(1)\n",
    "        fused_embed,_ = self.mhsa(visual_embedding,textual_embedding,visual_embedding)\n",
    "        normalize_fused_embed = self.layer_norm(fused_embed.squeeze(1)) + visual_embedding.squeeze(1)\n",
    "        layer_embed = self.layer_norm(self.fc(normalize_fused_embed)) + normalize_fused_embed\n",
    "        return layer_embed\n",
    "    \n",
    "class FusionAttentionModule(nn.Module):\n",
    "    def __init__(self, visual_dim, text_dim, num_layers = 3):\n",
    "        super().__init__()\n",
    "        self.fusion_layers = [FusionLayer(visual_dim,text_dim) for _ in range(num_layers)]\n",
    "    \n",
    "    def forward(self, visual_embedding, textual_embedding):\n",
    "        for layer in self.fusion_layers:\n",
    "            visual_embedding = layer(visual_embedding,textual_embedding)\n",
    "        return visual_embedding\n",
    "\n",
    "    \n",
    "class ComponentEncoder(nn.Module):\n",
    "    def __init__(self,num_layers=3,freeze_visual=True, freeze_textual=True):\n",
    "        super().__init__()\n",
    "        self.visual_encoder = DonutSwinModel.from_pretrained(\"./donut_encoder\")\n",
    "        self.textual_encoder = XLMRobertaModel.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
    "        if freeze_visual:\n",
    "            for p in self.visual_encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "        if freeze_textual:\n",
    "            for p in self.textual_encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "        self.fusion_module = FusionAttentionModule(self.visual_encoder.config.hidden_size,self.textual_encoder.config.hidden_size,num_layers)\n",
    "\n",
    "    def forward(self, image_inputs, text_inputs):\n",
    "        visual_embedding = self.visual_encoder(**image_inputs).pooler_output\n",
    "        textual_embedding = self.textual_encoder(**text_inputs).pooler_output\n",
    "        fused_embedding = self.fusion_module(visual_embedding,textual_embedding)\n",
    "        return fused_embedding\n",
    "    \n",
    "class ComponentDect(nn.Module):\n",
    "    def __init__(self, num_classes,num_layers=3,freeze_visual=True, freeze_textual=True,*args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.encoder = ComponentEncoder(num_layers,freeze_visual, freeze_textual)\n",
    "        self.fc = nn.Linear(self.encoder.visual_encoder.config.hidden_size,num_classes)\n",
    "\n",
    "    def forward(self, image_inputs, text_inputs):\n",
    "        embed = self.encoder(image_inputs, text_inputs)\n",
    "        pred = self.fc(embed)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComponentDect(\n",
       "  (encoder): ComponentEncoder(\n",
       "    (visual_encoder): DonutSwinModel(\n",
       "      (embeddings): DonutSwinEmbeddings(\n",
       "        (patch_embeddings): DonutSwinPatchEmbeddings(\n",
       "          (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "        )\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (encoder): DonutSwinEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): DonutSwinStage(\n",
       "            (blocks): ModuleList(\n",
       "              (0): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): Identity()\n",
       "                (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.005263158120214939)\n",
       "                (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): DonutSwinPatchMerging(\n",
       "              (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (1): DonutSwinStage(\n",
       "            (blocks): ModuleList(\n",
       "              (0): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.010526316240429878)\n",
       "                (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.015789475291967392)\n",
       "                (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): DonutSwinPatchMerging(\n",
       "              (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (2): DonutSwinStage(\n",
       "            (blocks): ModuleList(\n",
       "              (0): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.021052632480859756)\n",
       "                (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.02631578966975212)\n",
       "                (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (2): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.031578950583934784)\n",
       "                (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (3): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.03684210777282715)\n",
       "                (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (4): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.04210526496171951)\n",
       "                (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (5): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.04736842215061188)\n",
       "                (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (6): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.05263157933950424)\n",
       "                (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (7): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.057894736528396606)\n",
       "                (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (8): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.06315789371728897)\n",
       "                (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (9): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.06842105090618134)\n",
       "                (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (10): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.0736842080950737)\n",
       "                (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (11): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.07894736528396606)\n",
       "                (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (12): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.08421052992343903)\n",
       "                (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (13): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.08947368711233139)\n",
       "                (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (downsample): DonutSwinPatchMerging(\n",
       "              (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "              (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (3): DonutSwinStage(\n",
       "            (blocks): ModuleList(\n",
       "              (0): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.09473684430122375)\n",
       "                (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): DonutSwinLayer(\n",
       "                (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): DonutSwinAttention(\n",
       "                  (self): DonutSwinSelfAttention(\n",
       "                    (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): DonutSwinSelfOutput(\n",
       "                    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DonutSwinDropPath(p=0.10000000149011612)\n",
       "                (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (intermediate): DonutSwinIntermediate(\n",
       "                  (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                )\n",
       "                (output): DonutSwinOutput(\n",
       "                  (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): AdaptiveAvgPool1d(output_size=1)\n",
       "    )\n",
       "    (textual_encoder): XLMRobertaModel(\n",
       "      (embeddings): XLMRobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): XLMRobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x XLMRobertaLayer(\n",
       "            (attention): XLMRobertaAttention(\n",
       "              (self): XLMRobertaSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): XLMRobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): XLMRobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): XLMRobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): XLMRobertaPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (fusion_module): FusionAttentionModule()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = ComponentDect(num_classes=25,num_layers=1,freeze_textual=True, freeze_visual=True)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "epochs = 50\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3,weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,epochs,eta_min=1e-5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(pred, targets, alpha=0.25, gamma=2.0):\n",
    "    log_prob = torch.log_softmax(pred,dim=1)\n",
    "    one_hot_target = nn.functional.one_hot(targets,log_prob.shape[1])\n",
    "    weight = alpha*torch.pow(1- log_prob.exp(),gamma)\n",
    "    loss = torch.mean((-1*weight*log_prob)*one_hot_target)\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_dataloader, criterion, optimizer, image_processor, tokenizer, device):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for (images, texts, labels) in train_dataloader:\n",
    "        image_inputs = image_processor(images, return_tensors=\"pt\").to(device)\n",
    "        text_inputs = tokenizer(texts, return_tensors=\"pt\", padding=True).to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(image_inputs,text_inputs)\n",
    "        loss = criterion(pred,labels)\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss/len(train_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "def val(model,val_dataloader, criterion, image_processor, tokenizer, device):\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for (images, texts, labels) in val_dataloader:\n",
    "            image_inputs = image_processor(images, return_tensors=\"pt\").to(device)\n",
    "            text_inputs = tokenizer(texts, return_tensors=\"pt\", padding=True).to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = model(image_inputs,text_inputs)\n",
    "            loss = criterion(pred,labels)\n",
    "            total_loss += loss.item()\n",
    "            pred_classes = torch.argmax(pred,dim=1)\n",
    "            predictions.append(pred_classes.detach().cpu())\n",
    "            all_labels.append(labels.detach().cpu())\n",
    "    predictions = torch.concat(predictions,dim=0)\n",
    "    all_labels = torch.concat(all_labels,dim=0)\n",
    "    f1 = f1_score(all_labels.numpy(), predictions.numpy())\n",
    "    acc =accuracy_score(all_labels.numpy(), predictions.numpy())\n",
    "    return loss/len(train_dataloader), f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 2\u001b[0m     val_loss, f1, acc \u001b[38;5;241m=\u001b[39m \u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfocal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_processor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(model,train_dataloader,focal_loss,optimizer,image_processor,tokenizer,device)\n\u001b[1;32m      4\u001b[0m     val_loss, f1, acc \u001b[38;5;241m=\u001b[39m val(model,val_dataloader,focal_loss,image_processor,tokenizer,device)\n",
      "Cell \u001b[0;32mIn[21], line 12\u001b[0m, in \u001b[0;36mval\u001b[0;34m(model, val_dataloader, criterion, image_processor, tokenizer, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m text_inputs \u001b[38;5;241m=\u001b[39m tokenizer(texts, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 12\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred,labels)\n\u001b[1;32m     14\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[16], line 57\u001b[0m, in \u001b[0;36mComponentDect.forward\u001b[0;34m(self, image_inputs, text_inputs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_inputs, text_inputs):\n\u001b[0;32m---> 57\u001b[0m     embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(embed)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[16], line 45\u001b[0m, in \u001b[0;36mComponentEncoder.forward\u001b[0;34m(self, image_inputs, text_inputs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_inputs, text_inputs):\n\u001b[0;32m---> 45\u001b[0m     visual_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisual_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mimage_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpooler_output\n\u001b[1;32m     46\u001b[0m     textual_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtextual_encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtext_inputs)\u001b[38;5;241m.\u001b[39mpooler_output\n\u001b[1;32m     47\u001b[0m     fused_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfusion_module(visual_embedding,textual_embedding)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/transformers/models/donut/modeling_donut_swin.py:981\u001b[0m, in \u001b[0;36mDonutSwinModel.forward\u001b[0;34m(self, pixel_values, bool_masked_pos, head_mask, output_attentions, output_hidden_states, interpolate_pos_encoding, return_dict)\u001b[0m\n\u001b[1;32m    975\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdepths))\n\u001b[1;32m    977\u001b[0m embedding_output, input_dimensions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    978\u001b[0m     pixel_values, bool_masked_pos\u001b[38;5;241m=\u001b[39mbool_masked_pos, interpolate_pos_encoding\u001b[38;5;241m=\u001b[39minterpolate_pos_encoding\n\u001b[1;32m    979\u001b[0m )\n\u001b[0;32m--> 981\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dimensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    990\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    992\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/transformers/models/donut/modeling_donut_swin.py:806\u001b[0m, in \u001b[0;36mDonutSwinEncoder.forward\u001b[0;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, output_hidden_states, output_hidden_states_before_downsampling, always_partition, return_dict)\u001b[0m\n\u001b[1;32m    797\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    798\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    799\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    803\u001b[0m         always_partition,\n\u001b[1;32m    804\u001b[0m     )\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 806\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dimensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_partition\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    811\u001b[0m hidden_states_before_downsampling \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/transformers/models/donut/modeling_donut_swin.py:725\u001b[0m, in \u001b[0;36mDonutSwinStage.forward\u001b[0;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, always_partition)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer_module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[1;32m    723\u001b[0m     layer_head_mask \u001b[38;5;241m=\u001b[39m head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 725\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dimensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_partition\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    729\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    731\u001b[0m hidden_states_before_downsampling \u001b[38;5;241m=\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/transformers/models/donut/modeling_donut_swin.py:679\u001b[0m, in \u001b[0;36mDonutSwinLayer.forward\u001b[0;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, always_partition)\u001b[0m\n\u001b[1;32m    677\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm_after(hidden_states)\n\u001b[1;32m    678\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(layer_output)\n\u001b[0;32m--> 679\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m(layer_output)\n\u001b[1;32m    681\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m (layer_output, attention_outputs[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m (layer_output,)\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m layer_outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1918\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1920\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss = train(model,train_dataloader,focal_loss,optimizer,image_processor,tokenizer,device)\n",
    "    val_loss, f1, acc = val(model,val_dataloader,focal_loss,image_processor,tokenizer,device)\n",
    "    print(f'Epoch: {epoch} Train Loss: {train_loss} Val Loss: {val_loss} F1 score: {f1} Accuracy: {acc}')\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
