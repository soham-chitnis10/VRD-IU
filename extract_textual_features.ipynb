{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/VRD-IU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "class CompTextDataset(Dataset):\n",
    "    def __init__(self, pickle_file):\n",
    "        super().__init__()\n",
    "        with open(pickle_file, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "        self.components = []\n",
    "        for k in data.keys():\n",
    "            for comp in data[k]['components']:\n",
    "                if comp['bbox'] == [0.0, 0.0, 0.0, 0.0]:\n",
    "                  continue\n",
    "                self.components.append(comp)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.components)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comp = self.components[index]\n",
    "        try:\n",
    "            text = comp['text']\n",
    "        except:\n",
    "            text = comp['category']\n",
    "        return text, comp['object_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = CompVisualDataset('train_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaModel\n",
    "model = XLMRobertaModel.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using: {device}\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "def extract_features(dataloader, feature_path):\n",
    "  if not os.path.exists(feature_path):\n",
    "    os.makedirs(feature_path)\n",
    "  with torch.no_grad():\n",
    "      for texts, object_ids in tqdm(dataloader):\n",
    "          text_inputs = tokenizer(texts, return_tensors=\"pt\",padding=True, truncation=True).to(device)\n",
    "          outputs = model(**text_inputs)\n",
    "          features = outputs.pooler_output.detach().cpu()\n",
    "          for idx, obj_id in enumerate(object_ids):\n",
    "            torch.save(features[idx],os.path.join(feature_path,f\"{obj_id}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(subset,batch_size=256, collate_fn= collate_fn, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "extract_features(train_dataloader,  'train_textual_features')\n",
    "print(\"Extraction completed for training set!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
